import streamlit as st
import torch
import transformers
from dataset import BERTTestDataset
import os
import pandas as pd
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForSequenceClassification
# from model import Model

DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
# BASE_DIR = os.getcwd()
# DATA_DIR = os.path.join(BASE_DIR, '../data')
MODEL_DIR = '2024-level2-datacentric-nlp-8/basic-klue-bert-base'
TOKEN = 'huggingface token'
# MODEL_DIR = os.path.join(BASE_DIR, '../output/checkpoint-300')

def model_setup():
    # print('model setup')
    Tokenizer_NAME = "klue/bert-base"
    tokenizer = AutoTokenizer.from_pretrained(Tokenizer_NAME)

    model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR, use_auth_token=TOKEN, num_labels=7)
    # model.parameters

    model.to(DEVICE)
    model.eval()
    return model, tokenizer, DEVICE

def main():
    """
        Datacentric ì£¼ì œ ë¶„ë¥˜ í”„ë¡œì íŠ¸ - íŒ€ WIZARDS OF SENTENCES -
        íŒ€ ë™í–‰ì˜ RE(ê´€ê³„ ì¶”ì¶œ) Projectì˜ app.py ì½”ë“œ ì°¸ì¡°
    """
    st.markdown("<h2 style='text-align: center; color: red;'>NLP Data-Centric ğŸ¦†</h2>", unsafe_allow_html=True)

    st.session_state.category = None
    st.text_input('ë‰´ìŠ¤ì œëª©ì„ ì…ë ¥í•˜ì„¸ìš”', key='sentence')

    def fill_all_inputs():
        if not st.session_state.sentence:
            return False
        return True
    
    if st.button('ì¹´í…Œê³ ë¦¬ ì¶”ë¡ '):
        if not fill_all_inputs():
            st.warning('ëª¨ë“  ë¹ˆì¹¸ì„ ì±„ì›Œì£¼ì„¸ìš”')
        else:
            sentence = st.session_state.sentence

            demo_dataset = pd.DataFrame({'text':pd.Series([sentence,])})

            preds = []
            for idx, sample in tqdm(demo_dataset.iterrows()):
                inputs = tokenizer(sample['text'], return_tensors="pt").to(DEVICE)
                with torch.no_grad():
                    logits = model(**inputs).logits
                    pred = torch.argmax(torch.nn.Softmax(dim=1)(logits), dim=1).cpu().numpy()
                    preds.extend(pred)
                                
            num_to_label_dict = {0: 'ITê³¼í•™', 1: 'ê²½ì œ', 2: 'ì‚¬íšŒ', 3: 'ìƒí™œë¬¸í™”', 4: 'ì„¸ê³„', 5: 'ìŠ¤í¬ì¸ ', 6: 'ì •ì¹˜'}
            answer = num_to_label_dict[preds[0]]
            st.session_state.category = answer

    if st.session_state.category is not None:
        st.write('ì¹´í…Œê³ ë¦¬ ì˜ˆì¸¡ ê²°ê³¼ : ', st.session_state.category)


if __name__ == "__main__" :
    if 'model' not in st.session_state:
        st.session_state.model, st.session_state.tokenizer, st.session_state.device = model_setup()
    model = st.session_state.model
    tokenizer = st.session_state.tokenizer
    device = st.session_state.device
    
    main()
