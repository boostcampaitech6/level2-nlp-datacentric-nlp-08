{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile(n):\n",
    "    def percentile_(x):\n",
    "        return x.quantile(n)\n",
    "    percentile_.__name__ = 'percentile_{:02.0f}'.format(n*100)\n",
    "    \n",
    "    return percentile_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'klue/bert-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')\n",
    "train_data = pd.read_csv(\"../../data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 레이블 별 데이터 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    1000\n",
       "0    1000\n",
       "3    1000\n",
       "4    1000\n",
       "5    1000\n",
       "6    1000\n",
       "2    1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 샘플 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터 샘플 수 = 7000\n",
      "레이블 개수 = 7\n",
      "중복되는 샘플 수 = 0\n",
      "중복 제외 샘플 수 = 7000\n"
     ]
    }
   ],
   "source": [
    "print(\"총 데이터 샘플 수 =\", len(train_data))\n",
    "print(\"레이블 개수 =\", train_data['target'].nunique())\n",
    "\n",
    "print(\"중복되는 샘플 수 =\", sum(train_data.duplicated(keep=False, subset=['text'])))\n",
    "print(\"중복 제외 샘플 수 =\", train_data['text'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어 단위 문장 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 단위 문장 길이(95 percentile) = 9.0\n",
      "            len\n",
      "min    2.000000\n",
      "max   13.000000\n",
      "mean   6.545571\n"
     ]
    }
   ],
   "source": [
    "print(\"단어 단위 문장 길이(95 percentile) =\",\\\n",
    "      train_data['text'].apply(lambda x: len(x.split(' '))).agg([percentile(0.95)]).values[0])\n",
    "\n",
    "train_data['len'] = train_data['text'].apply(lambda x: len(x.split(' ')))\n",
    "print(train_data.agg({'len':['min', 'max', 'mean']}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토큰 단위 문장 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰 단위 문장 길이(95 percentile) = 21.0\n",
      "      token_len\n",
      "min    4.000000\n",
      "max   29.000000\n",
      "mean  15.547571\n"
     ]
    }
   ],
   "source": [
    "print(\"토큰 단위 문장 길이(95 percentile) =\",\\\n",
    "      train_data['text'].apply(lambda x: len(tokenizer(x)['input_ids'])).agg([percentile(0.95)]).values[0])\n",
    "\n",
    "train_data['token_len'] = train_data['text'].apply(lambda x: len(tokenizer(x)['input_ids']))\n",
    "print(train_data.agg({'token_len':['min', 'max', 'mean']}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## klue/bert-base가 알고 있는 특수 문자들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "klue/bert-base가 알고 있는 특수문자 개수 = 76\n",
      "defaultdict(<class 'int'>, {'·': 1135, '…': 2955, '.': 678, '%': 226, '↑': 70, '美': 218, '北': 203, '與': 31, '佛': 15, '外': 5, '人': 2, '朴': 97, '野': 23, 'ｍ': 4, '中': 112, '日': 55, '文': 29, '獨': 22, '⑤': 2, '∼': 61, '黨': 2, '⑥': 1, '靑': 52, '法': 1, '韓': 23, '女': 10, '前': 16, '詩': 5, '英': 36, '㎝': 11, '孫': 3, '→': 25, '①': 5, '反': 5, '㈜': 4, '對': 6, '黃': 4, '故': 2, '㎜': 11, '重': 2, 'ㆍ': 11, '④': 3, '軍': 9, '③': 5, '銀': 3, '％': 7, '族': 1, '安': 10, '證': 1, '金': 4, '②': 6, '㎞': 6, '㎡': 2, '車': 3, '大': 2, '戰': 1, '南': 5, '富': 1, '新': 1, '＋': 5, '行': 5, '親': 3, '‘': 1, '無': 2, '㎏': 1, '四': 1, '體': 1, '硏': 4, '色': 1, '强': 1, '℃': 1, '風': 2, '父': 2, '○': 4, '×': 1, '社': 1})\n"
     ]
    }
   ],
   "source": [
    "not_en_ko_num_pattern = re.compile('[^ㄱ-ㅎ가-힣a-zA-Z0-9\\s]')\n",
    "known_special_chars_dict = defaultdict(int)\n",
    "\n",
    "for sentence in train_data['text']:\n",
    "    special_chars = not_en_ko_num_pattern.findall(sentence)\n",
    "    if len(special_chars) != 0 :\n",
    "        for char in special_chars:\n",
    "            if tokenizer.tokenize(char) != ['[UNK]']:\n",
    "                known_special_chars_dict[char] += 1\n",
    "\n",
    "print(\"klue/bert-base가 알고 있는 특수문자 개수 =\", len(known_special_chars_dict))\n",
    "print(known_special_chars_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## klue/bert-base가 모르는 특수 문자들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "klue/bert-base가 모르는 특수문자 개수 = 36\n",
      "defaultdict(<class 'int'>, {'⅔': 6, '脫': 2, '伊': 18, '亞': 6, '⅓': 2, '↓': 33, '檢': 8, '展': 6, '曺': 2, '↔': 2, '企': 1, '核': 2, '㎛': 2, '秋': 1, '弗': 3, '潘': 1, '比': 2, '蘭': 1, '樂': 1, '勝': 1, '崔': 1, '號': 1, '₂': 1, '禹': 1, '⑫': 1, 'ｇ': 1, '駐': 1, '寒': 1, '賞': 1, '尹': 1, '港': 1, '印': 1, '⑪': 1, '千': 1, '協': 1, '㎓': 1})\n"
     ]
    }
   ],
   "source": [
    "not_en_ko_num_pattern = re.compile('[^ㄱ-ㅎ가-힣a-zA-Z0-9\\s]')\n",
    "unk_special_chars_dict = defaultdict(int)\n",
    "\n",
    "for sentence in train_data['text']:\n",
    "    special_chars = not_en_ko_num_pattern.findall(sentence)\n",
    "    if len(special_chars) != 0 :\n",
    "        for char in special_chars:\n",
    "            tokenizer.tokenize(char)\n",
    "            if tokenizer.tokenize(char) == ['[UNK]']:\n",
    "                unk_special_chars_dict[char] += 1\n",
    "\n",
    "print(\"klue/bert-base가 모르는 특수문자 개수 =\", len(unk_special_chars_dict))\n",
    "print(unk_special_chars_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
